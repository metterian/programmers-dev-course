## 밀도 추정(Density Estimattion)

**밀도 추정** : $N$ 개의 관찰 데이터(observations) $\mathbf{x}_{1}, \ldots \mathbf{x}_{N}$ 가 주어졌을 때 **분포함수** $p(\mathbf{x})$ 를 찾는 것을 말합니다. 

분포함수(확률분포)를 구할 수 있으면 모든 문제를 찾을 수 있습니다. 회귀문제, 분류문제 등 확률 분포를 통해 결합분포를 유도해 낼 수 있기 때문입니다. 밀도 추정을 하기 위해서는 다음과 같은 과정 혹은 전재조건이 필요합니다.

1. $p(\mathbf{x})$ 를 파라미터(매개변수)화(**parametric**) 된 분포로 가정한다. 분류문제에서는 주로 $p(t \mid \mathbf{x}), p(\mathcal{C} \mid \mathbf{x})$ 를 추정한다. 

   매개변수화 된 분포라고 불리는 이유는 이분포들이 몇개의 파라미터를 통해 확률 분포가 결정되기 때문입니다. 이말은 즉슨, 매개변수에 의해 확률분포가 변한다는 의미이고 즉, 매개변수를 찾기만 하면 확률분포를 찾을 수 있다는 말입니다.

2. 분포의 매개변수를 찾는다.
   1. **빈도주의 방법**(Frequentist's way): 어떤 기준(ex: 가능도)를 최적화 시키는 과정(최대우도법)을 통해 매개변수를 찾습니다. 
   2. **베이지언 방법**(Bayesian way): 먼저 파라미터의 사전확률(prior <u>distribution</u>)을 가정하고 베이즈 정리를 통해 매개변수의 사후확률(posterior <u>distribution</u>)을 구합니다.
3. 매개변수를 찾았다면(한 개의 값이든 분포든) 그것을 사용해서 "예측"을 할 수 있습니다. 



**켤레사전분포**(conjugate prior): 사후확률이 사전확률(분포)와 동일한 분포를 갖도록 해주는 것입니다.

켤러사전분포를 사용해서 사전확률과 사후확률의 분포가 같아지게 되면 계산이 용이하여 사용하는 것입니다. 



## 이항변수(Binary Variables) : 빈도주의 방법

이항 확률변수(binary random variable)인 $x$가 $x \in\{0,1\}$ 인 상황 (ex: 동전던지기)가 다음을 만족한다고 가정해 봅시다.
$$
\begin{aligned}
p(x=1 \mid \mu)&=\mu\\ p(x=0 \mid \mu)&=1-\mu
\end{aligned}
$$
앞서 밀도추정에서 이야기 했듯이 밀도추정을 위해서는 확률분포가 매개변수화된 분포로 가정해야 합니다. 때문에, 이산확률변수 $x$ 에 대한 확률 분포를 표현 해야 하고, 이때 확률변수를 확률 분포로 표현하기 위해 베이누이 분포를 따른다고 가정할 수 있습니다. 즉, $p(x)$ 는 베르누이 분포로 표현 될 수 있습니다. 
$$
\operatorname{Bern}(x \mid \mu)=\mu^{x}(1-\mu)^{1-x}
$$

### 베르누이 분포의 기댓값, 분산

베르누이 분포의 기댓값과 분산은 다음과 같습니다.

#### 기댓값

$$
\begin{aligned}
\mathbb{E}[x]&=\mu \\
&=0 \cdot(1-\mu)+1 \cdot \mu=\mu
\end{aligned}
$$



#### 분산

$$
\begin{aligned}
\operatorname{Var}[x] &=E\left[x^{2}\right]-E[x]^{2} \\
&=\{0 \cdot(1-\mu)+1 \cdot \mu\}-\mu^{2} \\
&=\mu-\mu^{2} \\
&=\mu(1-\mu)
\end{aligned}
$$



### 가능도 함수(likelihood funciton)

이렇게 베르누이 분포를 매개변수화(parametric) 시킨 후에 우리는 확률분포의 매개변수를 찾아야 합니다. 빈도주의 관점에서는 어떤 기준(가능도 함수)를 최적화 시키는 방법을 통해 매개변수를 찾는다고 했습니다. 

$x$ 값을 $N$ 번 관찰한 결과를 $\mathcal{D}=\left\{x_{1}, \ldots, x_{N}\right\}$ 라고 합시다. $x$ 가 독립적으로 $p(x \mid \mu)$ (매개변수 $\mu$ 가 주어졌을 때의 $x$ 가 뽑힐 확률)에서 뽑혀진다고 가정하면 다음과 같이 가능도함수(매개 변수 $\mu$ 의 함수인)를 만들 수 있습니다.
$$
p(\mathcal{D} \mid \mu)=\prod_{n=1}^{N} p\left(x_{n} \mid \mu\right)=\prod_{n=1}^{N} \mu^{x_{n}}(1-\mu)^{1-x_{n}}
$$

#### 빈도주의 방법

빈도주의 방법에서는 $\mu$ 값을 위 함수에서 최대화 시키는 값을 구할 수 있습니다. 이를 구하기 위해 로그 스케일 된 값에 $\mu$ 에 대한 편미분의 식을 0으로 놓고 풀면 다음과 같이 $\mu$를 구할 수 있습니다.
$$
\ln p(\mathcal{D} \mid \mu)=\sum_{n=1}^{N} \ln p\left(x_{n} \mid \mu\right)=\sum_{n=1}^{N}\left\{x_{n} \ln \mu+\left(1-x_{n}\right) \ln (1-\mu)\right\}
$$
$\mu$ 의 최대 가능도 추정치(maximum likelihood estimate)는 다음과 같습니다.
$$
\mu^{\mathrm{ML}}=\frac{1}{N}\sum_{n=1}^{N}{x_n}
$$
위의 식처럼 정리할 수 있고, 여기서 추정된 $\mu^{ML}$ 은 표본평균 이라고도 불립니다. 데이터에서 $x=1$인 관찰값(데이터)의 수를 $m$ 이라고 하면 다음의 형태로 다시 적을 수 있습니다.
$$
\mu^{\mathrm{ML}}=\frac{m}{N} \text { with } m=(\text { #observations of } x=1) 
$$
위 식에서 주의해야 할 점은 $N$ 이 작은 경우 위 MLE(최대 가능도)는 과적합(over-fitting) 된 결과를 야기 할 수 있습니다. 예를 들어 동전을 세번 던졌는데 세번이 다 앞면이 나왔다고 가정해 봅시다. 그러면 $N=m=3$ 이고 따라서, $\mu^{ML}=1$ 이 됩니다. 이경우 최대 가능도를 따라서 다음 값들을 예측하면 무조건 앞면이 나오게 됩니다. 이러한 상황이 최대 우도법을 사용했을때 발생할 수 있는 과적합 사례입니다. 

<br>

## 이항변수(Binary Variables) : 베이지안 방법

크기가 $N$의 데이터가 주어졌을때, 즉, 동전던지기를 $N$ 번 수행 했을때 앞면($x=1$)이 총 **몇 번**(확률변수)가 나왔는 지를 판단하는 문제로 고려 해봅시다. 이전에는 동전이 앞면이 나올지 뒷면이 나올지에만 관심이 있었다면, 이제는 앞면이 몇번 나올지가 궁금한 것입니다. 

위에서 구한 빈도주의 관점에서 베르누이 분포와 상황이 다소 비슷하지만 우리는 동전 던지기를 했을 때 앞면이 $m$ 번 나올 수 있는 모든 경우의 수를 구해야 합니다. 즉 조합을 사용해야 합니다. 이러한 조합을 사용한 분포를 **이항분포**(Binomial distiribution)이라고 합니다.
$$
\operatorname{Bin}(m \mid N, \mu)=\left(\begin{array}{c}
N \\
m
\end{array}\right) \mu^{m}(1-\mu)^{N-m}\\
\left(\begin{array}{c}
N \\
m
\end{array}\right) \equiv \frac{N !}{(N-m) ! m !}
$$
이항 분포와 베르누이 분포의 차이점을 살펴보면 앞에 조합이 추가 되었다는 점을 확인 할 수 있습니다. 조합을 사용하기 위해 기존에는 없었던 $m$이라는 매개변수가 추가 되었습니다. 즉, 빈도주위 관점과 베이지안 관점은 매개변수 차이라고 생각 할 수있습니다. 단, 여기서 $N$은 매개변수라고 생각하면 안됩니다. 주어진 데이터의 수라고 생각해야 합니다. 

$N=10$ 이고 $\mu=0.25$ 일때의 이항분포 결과를 살펴 봅시다.

<img src="http://norman3.github.io/prml/images/Figure2.1.png" alt="Figure2.1" style="zoom:23%;" />

위 분포에 대한 평균과 분산은 다음과 같습니다.
$$
E[m] \equiv \sum_{m=0}^{N} m \cdot \operatorname{Bin}(m \mid N, \mu)=N \mu\\
\operatorname{var}[m] \equiv \sum^{N}(m-E[m])^{2} \operatorname{Bin}(m \mid N, \mu)=N \mu(1-\mu)
$$


### 데이터를 보는 관점

빈도주의 관점과 베이지안 관점은 데이터를 바라로는 관점의 차이라고 생각 할 수 있습니다.

- 베르누이 시행의 반복: $x_{1}, \ldots, x_{N}$ 각각이 확률변수
- $x$ 가 1인 경우가 몇번 관찰 되었는가?(이항분포) : 하나의 확률 변수(관찰된 횟수) $m$

베지이안 방법을 쓰기 위해서는 데이터의 가능도를 구해야 하는데 이항분포를 가정하면 가능도 함수가 하나의 변수 $m$ 으로 ($x_{1}, \ldots, x_{N}$ 대신) 표현 가능해지므로 계산이 수훨해집니다. 



## 베타 분포(Beta Distribution)

앞에서 이항분포에서 MLE 를 통해 얻어진 $\mu$ 의 값이 표본 평균이라는 것을 확인 했습니다. ($\mu=\bar{x}$). 문제는 이러한 빈도주의적 관점에서 샘플 결과(표본 관측 데이터)에 대해 의존적이기 떄문에 표본이 모두 앞면이 나오면 $\mu = 1$ 이되어 과적합된 결과를 얻게 됩니다. 

이러한 문제를 해결하기 위해 기존의 MLE 방법이 아닌 베이지안 방식으로 매개변수를 추정하는 것을 살펴 볼 것입니다. 그 과정에서 필요한 부분은 바로 매개변수의 사전 확률 값 $p(\mu)$ 를 구하는 것입니다.  여기서 중요한점은 $p(\mu)$ 를 도입하면서 $\mu$를 상수가 아닌 랜덤 변수로 생각하는 것입니다. 

MLE에서는 매개변수를 고정된 값이지만, 알지 못하는 값으로 생각하고 이를 추정하는 문제로 이를 구했습니다. 전통적 통계학에서는 이러한 방식의 한계점을 개선 하기위해 특정한 한 지점의 값이 아니라 구간 추정 방식을 도입합니다. 즉, 매개변수를 하나의 값이 아니라 어떤 범위 내에 존재 할 것이다라고 예측 하는 것입니다. 반면, **베이지안 방식에서는 매개변수를 랜덤변수로 생각하여 일반적인 확률 분포로 다루게 됩니다.** 

그렇다면, 매개변수가 어떤 확률 분포를 가지다면 어떤 확률 분포로 가정하는 것이 좋을 까요? 동전 던지기 문제에서는 가능도 함수의 형태가 $\mu$ 와 $\mu(1-\mu)$ 의 형태로 